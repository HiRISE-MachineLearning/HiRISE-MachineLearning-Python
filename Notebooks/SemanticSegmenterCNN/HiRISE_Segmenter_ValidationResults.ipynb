{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script runs a trained semantic segmenter on HiRISE images using leave-one-region-out cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = ../../'\n",
    "presaved_folder = base_folder+'Data/Images/HiRISE_8bit_and_P4_mask/'\n",
    "\n",
    "PatchHeight = 4096 #enough to fit the entire width\n",
    "PatchWidth=4096\n",
    "NumChunksAcross = 1\n",
    "ExtraPaddingPixels = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select a GPU\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "\n",
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "import PIL\n",
    "import tensorflow\n",
    "import glob as glob\n",
    "print(\"tensorflow version = \",tensorflow.__version__)\n",
    "\n",
    "from p4tools import io\n",
    "from SemanticSegmentation import model_hrnet_P4,GetStats\n",
    "from P4_DataHandlers import GetMarkingsCentres,AddHeightBorderVal,CreateFullImageMasks,Load_P4_Data_PreSaved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get meta data information\n",
    "metadata_df = io.get_meta_data()\n",
    "\n",
    "#centres of fans and ellipses in P4 catalog\n",
    "MarkingsCentres_df = GetMarkingsCentres() #takes about 80 seconds\n",
    "\n",
    "#tiles \n",
    "Tiles_df = io.get_tile_coordinates()\n",
    "UniqueHiRiseImages = Tiles_df['obsid'].unique()\n",
    "print(\"Number of HiRise Images = \",UniqueHiRiseImages.shape[0])\n",
    "\n",
    "#regions\n",
    "region_names_df = io.get_region_names()\n",
    "region_names_df = region_names_df.set_index('obsid')\n",
    "region_names_df.at['ESP_012620_0975','roi_name'] = 'Buffalo'\n",
    "region_names_df.at['ESP_012277_0975','roi_name'] = 'Buffalo'\n",
    "region_names_df.at['ESP_012348_0975','roi_name'] = 'Taichung'\n",
    "\n",
    "#other meta data\n",
    "ImageResults_df = io.get_meta_data()\n",
    "ImageResults_df = ImageResults_df.set_index('OBSERVATION_ID')\n",
    "\n",
    "#join metadata and region data\n",
    "ImageResults_df = pd.concat([ImageResults_df, region_names_df], axis=1, sort=False)\n",
    "ImageResults_df=ImageResults_df.dropna()\n",
    "\n",
    "UniqueP4Regions = ImageResults_df['roi_name'].unique()\n",
    "print(\"Number of P4 regions = \",len(UniqueP4Regions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Tiles_df = io.get_tile_coordinates()\n",
    "Tiles_df['x_hirise']=Tiles_df['x_hirise'].astype('int')\n",
    "Tiles_df['y_hirise']=Tiles_df['y_hirise'].astype('int')\n",
    "\n",
    "TotalTiles = 0\n",
    "for Im in  UniqueHiRiseImages:\n",
    "    ThisImageTiles = Tiles_df[Tiles_df['obsid']==Im]\n",
    "    ThisImageTiles=ThisImageTiles.reset_index(drop=True)\n",
    "    TotalTiles = TotalTiles+ThisImageTiles.shape[0]\n",
    "Tiles_df.insert(0,'tile_id0',Tiles_df['tile_id'].values)\n",
    "Tiles_df.insert(1,'obsid0',Tiles_df['obsid'].values)\n",
    "Tiles_df.insert(2,'obsid1',Tiles_df['obsid'].values)\n",
    "for i in range(Tiles_df.shape[0]):\n",
    "    Tiles_df.at[i,'obsid1']=Tiles_df.at[i,'obsid1'][-4::]\n",
    "Tiles_df.insert(3,'region',Tiles_df['obsid'].values)\n",
    "Tiles_df.insert(4,'SOLAR_LONGITUDE',Tiles_df['obsid'].values)\n",
    "Tiles_df.insert(5,'START_TIME',Tiles_df['obsid'].values)\n",
    "Tiles_df.insert(6,'JI',np.zeros(TotalTiles))\n",
    "Tiles_df.insert(7,'Dice',np.zeros(TotalTiles))\n",
    "Tiles_df.insert(8,'Precision',np.zeros(TotalTiles))\n",
    "Tiles_df.insert(9,'Recall',np.zeros(TotalTiles))\n",
    "Tiles_df.insert(10,'TP',np.zeros(TotalTiles))\n",
    "Tiles_df.insert(11,'TN',np.zeros(TotalTiles))\n",
    "Tiles_df.insert(12,'FP',np.zeros(TotalTiles))\n",
    "Tiles_df.insert(13,'FN',np.zeros(TotalTiles))\n",
    "Tiles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create placeholder cols to hold model results \n",
    "ImageResults_df.insert(0,'Region name',np.empty(UniqueHiRiseImages.shape[0],dtype=np.str))\n",
    "ImageResults_df.insert(1,'Image name',np.empty(UniqueHiRiseImages.shape[0],dtype=np.str))\n",
    "ImageResults_df.insert(2,'JI',np.zeros(UniqueHiRiseImages.shape[0]))\n",
    "ImageResults_df.insert(3,'Dice',np.zeros(UniqueHiRiseImages.shape[0]))\n",
    "ImageResults_df.insert(4,'Area Ratio',np.zeros(UniqueHiRiseImages.shape[0]))\n",
    "ImageResults_df.insert(5,'Recall',np.zeros(UniqueHiRiseImages.shape[0]))\n",
    "ImageResults_df.insert(6,'Precision',np.zeros(UniqueHiRiseImages.shape[0]))\n",
    "ImageResults_df.insert(7,'TP',np.zeros(UniqueHiRiseImages.shape[0]))\n",
    "ImageResults_df.insert(8,'TN',np.zeros(UniqueHiRiseImages.shape[0]))\n",
    "ImageResults_df.insert(9,'FP',np.zeros(UniqueHiRiseImages.shape[0]))\n",
    "ImageResults_df.insert(10,'FN',np.zeros(UniqueHiRiseImages.shape[0]))\n",
    "ImageResults_df.insert(11,'Centre Correct',np.zeros(UniqueHiRiseImages.shape[0])) \n",
    "ImageResults_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all the models on left out validation regions - downloaded HiRISE Images:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ModelCount = 0\n",
    "model = model_hrnet_P4(3,2,16,0)\n",
    "for ToLeaveOut in UniqueP4Regions:\n",
    "\n",
    "    #select data for validation\n",
    "    LeaveOneRegionOutList = [n for n in UniqueP4Regions if n != ToLeaveOut]\n",
    "    print('running trained model ',str(ModelCount+1),' of ',str(len(UniqueP4Regions)),'; using leave out region: ',ToLeaveOut)\n",
    "\n",
    "    #load the model's weights for this left out region\n",
    "    model.load_weights(base_folder+'Data/Models/HiRISE_segmenter_leave_out_'+ToLeaveOut+'final.h5')\n",
    "\n",
    "    #load this region's images\n",
    "    [ImageList_val,Scales_val,ValImageNames,RegionNames] = Load_P4_Data_PreSaved(presaved_folder,\n",
    "                                                                      [ToLeaveOut],\n",
    "                                                                      ImageResults_df, #will be indexed by obs_id\n",
    "                                                                      Tiles_df) #will be indexed by obs_id\n",
    "    \n",
    "    #run the model on all loaded images, get stats, and optionally display and save prediction\n",
    "    CC=0\n",
    "    for val_im in ImageList_val:\n",
    "        \n",
    "        Im=ValImageNames[CC]\n",
    "        RegionInd = metadata_df.index[metadata_df['OBSERVATION_ID'] == Im].tolist()[0]\n",
    "        SolarLong = metadata_df.at[RegionInd,'SOLAR_LONGITUDE']\n",
    "        StartTime = metadata_df.at[RegionInd,'START_TIME']\n",
    "        print(Im,ToLeaveOut,SolarLong,StartTime)\n",
    "\n",
    "        \n",
    "        ImageResults_df.at[ValImageNames[CC],'Region name']=ToLeaveOut\n",
    "        ImageResults_df.at[ValImageNames[CC],'Image name']=ValImageNames[CC]\n",
    "\n",
    "        #images are too big to feed to neural network in one go, so chunk them\n",
    "        NumChunksDown = int(np.ceil(val_im.shape[0]/PatchHeight))\n",
    "        \n",
    "        #pad the image for running predictions on\n",
    "        Padded_val_im = 128*np.ones((1,NumChunksDown*PatchHeight,NumChunksAcross*PatchWidth,3),'uint8')   \n",
    "        WidthOffset =int((PatchWidth - val_im.shape[1])/2)\n",
    "        Padded_val_im[0,0:val_im.shape[0],WidthOffset:WidthOffset+val_im.shape[1],:] = val_im[:,:,0:3]\n",
    "        Padded_val_im = np.expand_dims(AddHeightBorderVal(Padded_val_im[0,:,:,:],ExtraPaddingPixels),0)\n",
    "\n",
    "        #don't pad the mask\n",
    "        val_mask = val_im[:,:,3]\n",
    "\n",
    "        #run the model\n",
    "        PredMask = np.zeros((Padded_val_im.shape[1],Padded_val_im.shape[2]),'uint8')\n",
    "        for i in range(NumChunksDown):\n",
    "            for j in range(NumChunksAcross):\n",
    "                InputIm = Padded_val_im[0:1,i*PatchHeight:(i+1)*PatchHeight,j*PatchWidth:(j+1)*PatchWidth,:]\n",
    "                PredMask[i*PatchHeight:(i+1)*PatchHeight,j*PatchWidth:(j+1)*PatchWidth] = np.argmax(np.squeeze(model.predict(InputIm)),axis=-1)\n",
    "\n",
    "        #take extra padding off\n",
    "        PredMask = PredMask[ExtraPaddingPixels:ExtraPaddingPixels+val_mask.shape[0],:]        \n",
    "        #take padding off the prediction mask\n",
    "        PredMask = PredMask[0:val_mask.shape[0],WidthOffset:WidthOffset+val_mask.shape[1]]\n",
    "        \n",
    "        #get stats\n",
    "        ImageResults_df.at[ValImageNames[CC],['JI','Dice','Area Ratio','Recall','Precision','TP','TN','FP','FN']]=GetStats(val_mask,PredMask)\n",
    "\n",
    "        #get stats on centres\n",
    "        CorrectCount = 0.0\n",
    "        This_df = MarkingsCentres_df[MarkingsCentres_df['Image Name']==ValImageNames[CC]]\n",
    "        for i in range(This_df.shape[0]):\n",
    "            if This_df['row'].values[i]<PredMask.shape[0] and This_df['column'].values[i]<PredMask.shape[1]:\n",
    "                if PredMask[This_df['row'].values[i],This_df['column'].values[i]]==1:\n",
    "                    CorrectCount=CorrectCount+1.0\n",
    "        ImageResults_df.at[ValImageNames[CC],'Centre Correct Fraction']=CorrectCount/This_df.shape[0]\n",
    "        ImageResults_df.at[ValImageNames[CC],'Centre Correct Count']=CorrectCount\n",
    "        ImageResults_df.at[ValImageNames[CC],'Centre P4 Count']=This_df.shape[0]\n",
    "            \n",
    "        ThisImageTiles = Tiles_df[Tiles_df['obsid']==Im]\n",
    "        ThisImageTiles=ThisImageTiles.reset_index(drop=True)\n",
    "        for i in range(ThisImageTiles.shape[0]):\n",
    "\n",
    "            #val_mask,PredMask\n",
    "            Start_col =int(ThisImageTiles.at[i,'x_hirise']-420)\n",
    "            Start_row =int(ThisImageTiles.at[i,'y_hirise']-324)\n",
    "            Tile_pred=PredMask[Start_row:min(Start_row+324,PredMask.shape[0]),Start_col:min(Start_col+420,PredMask.shape[1])]\n",
    "            Tile_truth=val_mask[Start_row:min(Start_row+324,PredMask.shape[0]),Start_col:min(Start_col+420,PredMask.shape[1])]\n",
    "\n",
    "            \n",
    "            JI,Dice,AreaRatio,Recall,Precision,TP,TN,FP,FN = GetStats(Tile_truth,Tile_pred)\n",
    "\n",
    "            Ind = Tiles_df.index[Tiles_df['tile_id0'] == ThisImageTiles.at[i,'tile_id']].tolist()[0]\n",
    "\n",
    "            Tiles_df.at[Ind,'region']=ToLeaveOut\n",
    "            Tiles_df.at[Ind,'SOLAR_LONGITUDE']=SolarLong\n",
    "            Tiles_df.at[Ind,'START_TIME']=StartTime\n",
    "            Tiles_df.at[Ind,'JI']=JI\n",
    "            Tiles_df.at[Ind,'Dice']=Dice\n",
    "            Tiles_df.at[Ind,'Recall']=Recall\n",
    "            Tiles_df.at[Ind,'Precision']=Precision\n",
    "            Tiles_df.at[Ind,'TP']=TP\n",
    "            Tiles_df.at[Ind,'TN']=TN\n",
    "            Tiles_df.at[Ind,'FP']=FP\n",
    "            Tiles_df.at[Ind,'FN']=FN\n",
    "            \n",
    "        CC=CC+1\n",
    "\n",
    "    ModelCount=ModelCount+1\n",
    "\n",
    "ImageResults_df=ImageResults_df.sort_values(['Region name','Image name'])\n",
    "ImageResults_df.to_csv('../../Data/SummaryResults/LORO_by_image.csv')\n",
    "Tiles_df.to_csv('../../Data/SummaryResults/Stats_by_tiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get stats by region\n",
    "RegionResults_df = pd.DataFrame()\n",
    "for group_name, df_group in  ImageResults_df.groupby('Region name'):\n",
    "    RegionResults_df.at[group_name,'NumImages']=df_group.shape[0]\n",
    "    RegionResults_df.at[group_name,'Total TP']=df_group['TP'].sum()\n",
    "    RegionResults_df.at[group_name,'Total FP']=df_group['FP'].sum()\n",
    "    RegionResults_df.at[group_name,'Total FN']=df_group['FN'].sum()\n",
    "    RegionResults_df.at[group_name,'Total TN']=df_group['TN'].sum()\n",
    "    RegionResults_df.at[group_name,'Total Centre P4 Count']=df_group['Centre P4 Count'].sum()\n",
    "    RegionResults_df.at[group_name,'Total Centre Correct Count']=df_group['Centre Correct Count'].sum()\n",
    "    RegionResults_df.at[group_name,'Region JI']=df_group['TP'].sum()/(df_group['TP'].sum()+df_group['FN'].sum()+df_group['FP'].sum())\n",
    "    RegionResults_df.at[group_name,'Region Dice']=2*df_group['TP'].sum()/(2*df_group['TP'].sum()+df_group['FN'].sum()+df_group['FP'].sum())\n",
    "    RegionResults_df.at[group_name,'Region Precision']=df_group['TP'].sum()/(df_group['TP'].sum()+df_group['FP'].sum())\n",
    "    RegionResults_df.at[group_name,'Region Recall']=df_group['TP'].sum()/(df_group['TP'].sum()+df_group['FN'].sum())\n",
    "    RegionResults_df.at[group_name,'Region Area Ratio']=(df_group['TP'].sum()+df_group['FN'].sum())/(df_group['TP'].sum()+df_group['FP'].sum())\n",
    "    RegionResults_df.at[group_name,'Region Centre Correct Fraction']=df_group['Centre Correct Count'].sum()/df_group['Centre P4 Count'].sum()\n",
    "    \n",
    "    #per image stats\n",
    "    RegionResults_df.at[group_name,'Median JI']=df_group['JI'].median()\n",
    "    RegionResults_df.at[group_name,'Median Dice']=df_group['Dice'].median()\n",
    "    RegionResults_df.at[group_name,'Median Precision']=df_group['Precision'].median()\n",
    "    RegionResults_df.at[group_name,'Median Recall']=df_group['Recall'].median()\n",
    "    RegionResults_df.at[group_name,'Median Area Ratio']=df_group['Area Ratio'].median()\n",
    "    RegionResults_df.at[group_name,'Median Centre Correct Fraction']=df_group['Centre Correct Fraction'].median()\n",
    "    \n",
    "    RegionResults_df.at[group_name,'Max JI']=df_group['JI'].max()\n",
    "    RegionResults_df.at[group_name,'Max Dice']=df_group['Dice'].max()\n",
    "    RegionResults_df.at[group_name,'Max Precision']=df_group['Precision'].max()\n",
    "    RegionResults_df.at[group_name,'Max Recall']=df_group['Recall'].max()\n",
    "    RegionResults_df.at[group_name,'Max Area Ratio']=df_group['Area Ratio'].max()\n",
    "    RegionResults_df.at[group_name,'Max Centre Correct Fraction']=df_group['Centre Correct Fraction'].max()\n",
    "    \n",
    "    RegionResults_df.at[group_name,'Min JI']=df_group['JI'].min()\n",
    "    RegionResults_df.at[group_name,'Min Dice']=df_group['Dice'].min()\n",
    "    RegionResults_df.at[group_name,'Min Precision']=df_group['Precision'].min()\n",
    "    RegionResults_df.at[group_name,'Min Recall']=df_group['Recall'].min()\n",
    "    RegionResults_df.at[group_name,'Min Area Ratio']=df_group['Area Ratio'].min()\n",
    "    RegionResults_df.at[group_name,'Min Centre Correct Fraction']=df_group['Centre Correct Fraction'].min()\n",
    "RegionResults_df=RegionResults_df.sort_values('NumImages')\n",
    "RegionResults_df.to_csv('../../Data/SummaryResults/LORO.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegionResults_df['Region Dice'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
