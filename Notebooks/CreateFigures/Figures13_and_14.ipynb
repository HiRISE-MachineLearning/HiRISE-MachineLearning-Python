{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix,balanced_accuracy_score,roc_auc_score,roc_curve\n",
    "from p4tools import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResultsPath = '../../Data/SummaryResults/'\n",
    "FiguresPath = '../../Data/Figures/'\n",
    "if not os.path.isdir(FiguresPath):\n",
    "    os.mkdir(FiguresPath)\n",
    "    \n",
    "NumRepeats=3\n",
    "\n",
    "ResultsList=[]\n",
    "for Rep in range(NumRepeats):\n",
    "    ResultsList.append(pd.read_csv(ResultsPath+'TileClassifier_LORO_final_repeat'+str(Rep)+'.csv'))\n",
    "    \n",
    "Y_true=ResultsList[-1]['GroundTruth'].astype('uint8')\n",
    "\n",
    "Y_pred=ResultsList[0]['ClassifierConf'].values\n",
    "for Rep in range(1,NumRepeats):\n",
    "    Y_pred=Y_pred+ResultsList[Rep]['ClassifierConf'].values\n",
    "Y_pred=Y_pred/NumRepeats\n",
    "\n",
    "Results_df = ResultsList[-1]\n",
    "Results_df['ClassifierConf']=Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall95PC_Threshold=0.24\n",
    "\n",
    "AUC = roc_auc_score(Y_true, Y_pred)\n",
    "conf_matrix = confusion_matrix(Y_true,Y_pred>Recall95PC_Threshold,labels=[0,1])\n",
    "Sensitivity = conf_matrix[1,1]/(conf_matrix[1,0]+conf_matrix[1,1])\n",
    "Specificity = conf_matrix[0,0]/(conf_matrix[0,0]+conf_matrix[0,1])\n",
    "Precision = conf_matrix[1,1]/(conf_matrix[1,1]+conf_matrix[0,1])\n",
    "Balanced_accuracy = balanced_accuracy_score(Y_true, Y_pred>Recall95PC_Threshold)\n",
    "\n",
    "print('Number of tiles classified in Leave-One-Region-Out Cross-Validation= ',Results_df.shape[0])\n",
    "print('')\n",
    "print('Confusion matrix = ')\n",
    "print(conf_matrix)\n",
    "print('')\n",
    "print('sensitivity=',round(100*Sensitivity,1),'%')\n",
    "print('Specificity=',round(100*Specificity,1),'%')\n",
    "print('Precision=',round(100*Precision,1),'%')\n",
    "print('AUC=',round(AUC,2))\n",
    "print('Balanced Accuracy =',round(100*Balanced_accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "fpr, tpr, thresholds = roc_curve(Y_true, Y_pred)\n",
    "plt.plot(1-fpr,tpr,linewidth=3)\n",
    "plt.xlabel('Specificity',fontsize=20)\n",
    "plt.ylabel('Recall',fontsize=20)\n",
    "\n",
    "plt.plot(Specificity,Sensitivity,'og',linewidth=30,markersize=20)\n",
    "\n",
    "plt.text(0.5, 0.5, 'AUC='+str(round(AUC,2)), fontsize=20)\n",
    "plt.text(0.2, 0.9, '95% recall point at', fontsize=20,color='green')\n",
    "plt.text(0.2, 0.85, '53% specificity', fontsize=20,color='green')\n",
    "\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(FiguresPath+'Figure13.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regions\n",
    "region_names_df = io.get_region_names()\n",
    "region_names_df = region_names_df.set_index('obsid')\n",
    "region_names_df.at['ESP_012620_0975','roi_name'] = 'Buffalo'\n",
    "region_names_df.at['ESP_012277_0975','roi_name'] = 'Buffalo'\n",
    "region_names_df.at['ESP_012348_0975','roi_name'] = 'Taichung'\n",
    "\n",
    "#other meta data\n",
    "ImageResults_df = io.get_meta_data()\n",
    "ImageResults_df = ImageResults_df.set_index('OBSERVATION_ID')\n",
    "ImageResults_df = pd.concat([ImageResults_df, region_names_df], axis=1, sort=False)\n",
    "ImageResults_df=ImageResults_df.dropna()\n",
    "UniqueP4Regions = ImageResults_df['roi_name'].unique()\n",
    "print(\"Number of P4 regions = \",len(UniqueP4Regions))\n",
    "\n",
    "BAs=[]\n",
    "for ToLeaveOut in UniqueP4Regions:\n",
    "    This_df = Results_df[Results_df['Region']==ToLeaveOut]\n",
    "    y_true = This_df['GroundTruth'].values\n",
    "    y_pred = This_df['ClassifierConf'].values\n",
    "    Balanced_accuracy_cl = balanced_accuracy_score(y_true, y_pred>0.5)\n",
    "    BAs.append(Balanced_accuracy_cl)\n",
    "regions_sorted=[x for y, x in sorted(zip(BAs,UniqueP4Regions))]\n",
    "\n",
    "fig=plt.figure(figsize=(15,15))\n",
    "plt.bar(regions_sorted,100*np.array(sorted(BAs)))\n",
    "ax=fig.gca()\n",
    "ax.set_xticks(np.arange(0,len(regions_sorted)))\n",
    "ax.set_xticklabels(regions_sorted,rotation=90,fontsize=20)\n",
    "ax.set_ylabel('Balanced Accuracy (%)',fontsize=30)\n",
    "matplotlib.rc('xtick', labelsize=30) \n",
    "matplotlib.rc('ytick', labelsize=30)\n",
    "fig.tight_layout()\n",
    "plt.savefig(FiguresPath+'Figure14.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
